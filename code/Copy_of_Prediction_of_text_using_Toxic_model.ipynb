{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5Hsr0a9Md2-"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_features = 13522\n",
        "max_len = 250\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/model4.hdf5')\n",
        "weights = load_model('/content/drive/MyDrive/model4.hdf5').get_weights()\n",
        "model.set_weights(weights)\n",
        "\n",
        "text\n",
        "\n",
        "tokenizer = Tokenizer(max_features)\n",
        "\n",
        "# load the saved tokenizer\n",
        "with open('/content/drive/MyDrive/tokenizerOf_ToxicModel.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "tokenized_sentences = tokenizer.texts_to_sequences([text]) \n",
        "\n",
        "words = tokenizer.sequences_to_texts(tokenized_sentences)\n",
        "print(words)\n",
        "\n",
        "train_padding = pad_sequences(tokenized_sentences, max_len)\n",
        "\n",
        "prediction = model.predict(train_padding)\n",
        "\n",
        "id = np.argmax(prediction)\n",
        "\n",
        "if id is 0:\n",
        "  print(\"it is normal\")\n",
        "if id is 1:\n",
        "  print(\"it is abusive\")\n",
        "if id is 2:\n",
        "  print(\"it is Threat\")  "
      ]
    }
  ]
}